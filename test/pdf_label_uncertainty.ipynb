{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d0d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import CascadeForestClassifier\n",
    "import PRF4DF\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# --- Seed setting ---\n",
    "seed = 123\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8f7866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Data ---\n",
      "Original X sample shape:  (1000, 17)\n",
      "Original py_original sample shape:  (1000, 17)\n",
      "1000 objects, 17 original features, 17 classes\n"
     ]
    }
   ],
   "source": [
    "# --- Data loading ---\n",
    "X = np.load('../data/bootstrap_X.npy')\n",
    "\n",
    "X = X[:1000]\n",
    "\n",
    "# --- Label Generation ---\n",
    "# Random probabilities for 17 classes\n",
    "py_original = np.array([np.random.dirichlet(np.ones(17)).tolist() for _ in range(1000)])\n",
    "y_discrete = np.argmax(py_original, axis=1)\n",
    "\n",
    "# --- Configuration Flags ---\n",
    "use_feature_uncertainties_mode = False\n",
    "use_probabilistic_labels_mode = True\n",
    "\n",
    "print(\"--- Original Data ---\")\n",
    "print(\"Original X sample shape: \", X.shape)\n",
    "print(\"Original py_original sample shape: \", py_original.shape)\n",
    "\n",
    "n_objects = X.shape[0]\n",
    "n_features_X_orig = X.shape[1]\n",
    "n_classes = py_original.shape[1]\n",
    "print(f\"{n_objects} objects, {n_features_X_orig} original features, {n_classes} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "484adf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data splitting ---\n",
    "n_train = int(n_objects * 0.8)\n",
    "n_test = int(n_objects - n_train)\n",
    "\n",
    "shuffled_inds = np.random.permutation(n_objects)\n",
    "\n",
    "train_inds = shuffled_inds[:n_train]\n",
    "X_train = X[train_inds][:, :n_features_X_orig]\n",
    "y_train_discrete = y_discrete[train_inds]\n",
    "py_train = py_original[train_inds]\n",
    "\n",
    "test_inds = shuffled_inds[n_train:(n_train + n_test)]\n",
    "X_test = X[test_inds][:, :n_features_X_orig]\n",
    "y_test_discrete = y_discrete[test_inds]\n",
    "py_test = py_original[test_inds]\n",
    "\n",
    "# Concatenate parts of X_combined dynamically\n",
    "parts_train = [X_train]\n",
    "parts_test = [X_test]\n",
    "\n",
    "parts_train.append(py_train)\n",
    "parts_test.append(py_test)\n",
    "\n",
    "X_train_combined = np.hstack(parts_train)\n",
    "X_test_combined = np.hstack(parts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1999de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model training ---\n",
    "\n",
    "n_cascade_estimators = 4\n",
    "model = CascadeForestClassifier(\n",
    "    n_bins=n_classes,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# PRF (estimators)\n",
    "prf_estimators = []\n",
    "for i in range(n_cascade_estimators):\n",
    "    single_prf_estimator = PRF4DF.SklearnCompatiblePRF(\n",
    "        n_classes_= n_classes,\n",
    "        n_features_= n_features_X_orig,\n",
    "        use_probabilistic_labels=use_probabilistic_labels_mode,\n",
    "        use_feature_uncertainties=use_feature_uncertainties_mode,\n",
    "        n_estimators=10,\n",
    "        max_depth=10,\n",
    "        random_state=i,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    prf_estimators.append(single_prf_estimator)\n",
    "\n",
    "# Set the PRF estimators to the DF model\n",
    "model.set_estimator(prf_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c082cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting...\n",
      "[2025-06-05 17:48:08.421] Start to fit the model:\n",
      "[2025-06-05 17:48:08.422] Fitting cascade layer = 0 \n",
      "[2025-06-05 17:48:17.769] layer = 0  | Val Acc = 7.000 % | Elapsed = 9.347 s\n",
      "[2025-06-05 17:48:17.784] Fitting cascade layer = 1 \n",
      "[2025-06-05 17:48:28.340] layer = 1  | Val Acc = 6.250 % | Elapsed = 10.556 s\n",
      "[2025-06-05 17:48:28.340] Early stopping counter: 1 out of 2\n",
      "[2025-06-05 17:48:28.354] Fitting cascade layer = 2 \n",
      "[2025-06-05 17:48:38.867] layer = 2  | Val Acc = 5.625 % | Elapsed = 10.514 s\n",
      "[2025-06-05 17:48:38.867] Early stopping counter: 2 out of 2\n",
      "[2025-06-05 17:48:38.867] Handling early stopping\n",
      "[2025-06-05 17:48:38.885] The optimal number of layers: 1\n"
     ]
    }
   ],
   "source": [
    "# --- Model fitting ---\n",
    "print(\"Starting model fitting...\")\n",
    "model.fit(X=X_train_combined, y=y_train_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ad15074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-05 17:49:11.486] Start to evalute the model:\n",
      "[2025-06-05 17:49:11.487] Evaluating cascade layer = 0 \n",
      "Testing Accuracy: 8.000 %\n"
     ]
    }
   ],
   "source": [
    "# --- Model evaluation ---\n",
    "accuracy = model.score(X_test_combined, y_test_discrete) * 100\n",
    "print(f\"Testing Accuracy: {accuracy:.3f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
