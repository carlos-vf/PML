{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6d0d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepforest as df\n",
    "import os\n",
    "import PRF4DF\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# --- Seed setting ---\n",
    "seed = 129\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af8f7866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Data ---\n",
      "Original X sample:  [[ 0.33453338  0.3817734   0.19323093 ... -0.81191589  0.19067206\n",
      "   0.84772759]\n",
      " [ 0.32742773  0.35012285  0.17785153 ... -0.85643206  0.19620735\n",
      "   0.85023905]\n",
      " [ 0.39173798  0.32019704  0.17513842 ...  0.23618577  0.20204299\n",
      "   0.79843681]\n",
      " ...\n",
      " [ 0.43071606  0.37988827  0.24714295 ... -0.84221529  0.24334545\n",
      "   0.8628581 ]\n",
      " [ 0.18695281  0.28667433  0.1404702  ...  1.19362455  0.09216904\n",
      "   0.77052006]\n",
      " [ 0.12773789  0.30903322  0.15816711 ...  0.52400894  0.06605999\n",
      "   0.79830589]]\n",
      "Original dX sample:  [[0.00980023 0.01298663 0.01730336 ... 0.07554966 0.00503042 0.00614086]\n",
      " [0.0099433  0.01547131 0.01834346 ... 0.06557894 0.00303583 0.00408301]\n",
      " [0.00952382 0.00953937 0.0162304  ... 0.15137843 0.00276635 0.00701187]\n",
      " ...\n",
      " [0.01513477 0.01971204 0.01964974 ... 0.12579423 0.00383432 0.00537172]\n",
      " [0.01069045 0.00748945 0.0150812  ... 0.43512693 0.00363849 0.00970247]\n",
      " [0.00616469 0.01622886 0.01385321 ... 0.36720489 0.00177792 0.0100949 ]]\n",
      "Original y sample:  [2 0 2 0 2 0 2 0 0 2 2 0 1 0 2 1 2 2 2 0 0 0 2 2 2 2 0 0 2 0 0 2 2 2 2 1 1\n",
      " 0 2 0 2 0 0 2 0 2 0 0 2 0 1 1 2 0 2 2 2 2 0 2 2 2 2 0 2 0 0 0 1 2 2 2 1 2\n",
      " 2 0 2 2 2 0 0 2 0 2 2 2 0 2 0 2 1 2 0 2 0 0 2 2 0 0 0 0 0 0 2 1 0 2 0 0 2\n",
      " 2 1 2 1 1 2 0 2 2 0 0 2 1 2 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 2 0 0 2 2 0 0\n",
      " 0 0 2 0 0 0 0 0 2 2 2 2 0 0 0 2 2 0 0 2 2 0 2 2 0 0 0 0 2 2 0 0 2 2 2 2 2\n",
      " 2 2 0 0 2 2 2 2 2 1 2 2 0 2 0 0 0 2 1 2 0 1 1 2 2 0 1 0 2 2 0 2 0 2 0 2 1\n",
      " 1 2 0 2 2 1 0 2 0 0 0 0 0 0 2 1 0 0 0 0 0 1 0 0 0 0 0 2 0 0 1 0 2 0 0 0 0\n",
      " 0 0 0 2 0 2 2 0 2 0 0 2 2 1 2 0 0 2 2 0 0 1 2 1 0 1 2 0 0 0 2 0 0 0 0 2 2\n",
      " 0 2 2 0 2 0 0 0 0 0 2 1 0 1 0 0 0 2 0 0 0 1 0 0 0 0 0 2 2 0 0 0 0 0 2 0 2\n",
      " 0 0 0 0 0 0 1 2 1 2 2 1 2 0 2 0 1 1 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 1 1 2 2\n",
      " 2 1 0 0 2 0 1 0 0 2 0 0 2 0 0 0 2 0 2 0 0 2 0 2 0 0 1 2 0 0 1 0 2 0 2 2 2\n",
      " 2 0 0 0 2 2 0 0 2 0 0 2 2 0 0 0 2 0 2 2 0 0 1 0 0 1 0 2 2 0 1 0 1 0 2 2 1\n",
      " 0 0 0 2 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 2 0 0 0 2 0 0 0 0 0 0\n",
      " 2 0 2 0 0 0 0 2 0 2 1 2 2 2 0 2 2 2 0 0 2 0 1 0 2 2 2 1 0 0 0 0 0 2 0 2 0\n",
      " 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 2 2 0 1 0 0 0 0 2 0\n",
      " 1 2 0 0 0 0 0 2 0 2 2 0 1 0 0 0 1 2 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 2 2 2 0\n",
      " 0 0 2 2 2 0 0 0 0 0 2 0 0 1 1 1 2 0 0 0 2 2 2 2 0 0 0 2 2 2 0 2 0 2 2 2 2\n",
      " 1 2 2 2 1 2 0 2 0 2 2 0 0 0 0 0 2 2 1 0 2 0 0 0 0 0 2 0 0 0 0 2 0 0 0 2 0\n",
      " 0 0 0 0 0 2 0 2 0 0 2 0 2 0 2 0 0 0 1 0 1 0 2 2 2 1 0 0 0 0 0 2 1 1 0 0 0\n",
      " 1 0 0 0 0 0 1 2 2 0 0 0 0 2 0 0 2 0 0 2 0 0 0 0 0 0 2 0 1 0 2 0 0 0 1 2 0\n",
      " 1 0 0 0 0 0 2 1 0 1 2 0 0 1 0 0 0 1 2 0 2 1 2 0 1 0 2 0 0 1 0 0 0 0 0 0 0\n",
      " 0 2 0 1 0 0 0 0 0 1 0 0 0 0 0 0 2 2 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 1 0 0 2\n",
      " 2 0 0 0 0 0 0 0 0 0 1 0 1 0 0 2 2 0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 2 0 0 0 1 2 1 0 0 0 0 2 0 0 0 0 0 1 0 0 0 2 0 1 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 2 0 2 0 0 0 2 0 2 1 0 0 0\n",
      " 2 0 1 2 0 2 0 0 0 0 0 1 0 0 0 2 0 0 2 0 0 0 0 2 0 0 1 2 1 0 1 0 0 2 0 0 0\n",
      " 0 2 0 0 0 1 0 2 0 0 2 2 0 2 0 0 0 0 0 1 0 0 2 0 1 2 0 1 1 0 0 2 0 0 0 2 1\n",
      " 2]\n",
      "Unique labels in y:  {0, 1, 2}\n",
      "1000 objects, 17 features\n"
     ]
    }
   ],
   "source": [
    "# --- Data loading ---\n",
    "X = np.load('../data/bootstrap_X.npy')\n",
    "dX = np.load('../data/bootstrap_dX.npy')\n",
    "y = np.load('../data/bootstrap_y.npy')\n",
    "\n",
    "X = X[:1000]\n",
    "dX = dX[:1000]\n",
    "y = y[:1000]\n",
    "y[y > 2] = 2\n",
    "\n",
    "#dX = np.zeros(shape=(2000,17))\n",
    "print(\"--- Original Data ---\")\n",
    "print(\"Original X sample: \", X)\n",
    "print(\"Original dX sample: \", dX)\n",
    "print(\"Original y sample: \", y)\n",
    "print(\"Unique labels in y: \", set(y))\n",
    "\n",
    "n_objects = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "n_classes = len(set(y))\n",
    "print(f\"{n_objects} objects, {n_features} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "484adf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size = 800, Test set size = 200\n"
     ]
    }
   ],
   "source": [
    "# --- Data splitting ---\n",
    "n_train = int(n_objects * 0.8)\n",
    "n_test =  int(n_objects - n_train)\n",
    "print(f'Train set size = {n_train}, Test set size = {n_test}')\n",
    "\n",
    "shuffled_inds = np.random.permutation(n_objects)\n",
    "\n",
    "train_inds = shuffled_inds[:n_train]\n",
    "X_train = X[train_inds][:, :n_features]\n",
    "dX_train = dX[train_inds][:, :n_features] \n",
    "y_train = y[train_inds]\n",
    "\n",
    "test_inds = shuffled_inds[n_train:(n_train + n_test)]\n",
    "X_test = X[test_inds][:, :n_features]\n",
    "dX_test = dX[test_inds][:, :n_features]\n",
    "y_test = y[test_inds]\n",
    "\n",
    "# Concatenate X and dX for training\n",
    "X_train_combined = np.hstack((X_train, dX_train))\n",
    "X_test_combined = np.hstack((X_test, dX_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1999de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model training ---\n",
    "\n",
    "# DeepForest\n",
    "n_cascade_estimators = 2  # Forests per layer\n",
    "model = df.CascadeForestClassifier(\n",
    "    n_bins=n_classes,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "\n",
    "# PRF (estimators)\n",
    "prf_estimators = []\n",
    "for i in range(n_cascade_estimators):\n",
    "    single_prf_estimator = PRF4DF.SklearnCompatiblePRF(\n",
    "        n_classes_= n_classes,\n",
    "        n_features_= n_features,\n",
    "        use_probabilistic_labels=False, \n",
    "        use_feature_uncertainties=True,\n",
    "        n_estimators=10, # Trees per forest\n",
    "        max_depth=10,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    prf_estimators.append(single_prf_estimator)\n",
    "\n",
    "# Set the PRF estimators to the DF model\n",
    "model.set_estimator(prf_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c082cf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model fitting...\n",
      "[2025-06-09 14:24:29.376] Start to fit the model:\n",
      "[2025-06-09 14:24:29.376] Fitting cascade layer = 0 \n",
      "[2025-06-09 14:24:33.061] layer = 0  | Val Acc = 74.375 % | Elapsed = 3.685 s\n",
      "[2025-06-09 14:24:33.062] Fitting cascade layer = 1 \n",
      "[2025-06-09 14:24:37.161] layer = 1  | Val Acc = 73.125 % | Elapsed = 4.099 s\n",
      "[2025-06-09 14:24:37.161] Early stopping counter: 1 out of 2\n",
      "[2025-06-09 14:24:37.162] Fitting cascade layer = 2 \n",
      "[2025-06-09 14:24:41.176] layer = 2  | Val Acc = 72.125 % | Elapsed = 4.015 s\n",
      "[2025-06-09 14:24:41.176] Early stopping counter: 2 out of 2\n",
      "[2025-06-09 14:24:41.176] Handling early stopping\n",
      "[2025-06-09 14:24:41.181] The optimal number of layers: 1\n"
     ]
    }
   ],
   "source": [
    "# --- Model fitting ---\n",
    "print(\"Starting model fitting...\")\n",
    "model.fit(X=X_train_combined, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ad15074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-09 14:24:48.952] Start to evalute the model:\n",
      "[2025-06-09 14:24:48.953] Evaluating cascade layer = 0 \n",
      "Testing Accuracy: 76.500 %\n"
     ]
    }
   ],
   "source": [
    "# --- Model evaluation ---\n",
    "accuracy = model.score(X_test_combined, y_test) * 100\n",
    "print(f\"Testing Accuracy: {accuracy:.3f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bde1e508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\n",
      "[2025-06-09 14:24:53.126] Start to fit the model:\n",
      "[2025-06-09 14:24:53.126] Fitting cascade layer = 0 \n",
      "[2025-06-09 14:24:53.168] layer = 0  | Val Acc = 72.375 % | Elapsed = 0.042 s\n",
      "[2025-06-09 14:24:53.171] Fitting cascade layer = 1 \n",
      "[2025-06-09 14:24:53.210] layer = 1  | Val Acc = 74.125 % | Elapsed = 0.039 s\n",
      "[2025-06-09 14:24:53.212] Fitting cascade layer = 2 \n",
      "[2025-06-09 14:24:53.254] layer = 2  | Val Acc = 71.625 % | Elapsed = 0.041 s\n",
      "[2025-06-09 14:24:53.254] Early stopping counter: 1 out of 2\n",
      "[2025-06-09 14:24:53.256] Fitting cascade layer = 3 \n",
      "[2025-06-09 14:24:53.297] layer = 3  | Val Acc = 70.625 % | Elapsed = 0.041 s\n",
      "[2025-06-09 14:24:53.297] Early stopping counter: 2 out of 2\n",
      "[2025-06-09 14:24:53.297] Handling early stopping\n",
      "[2025-06-09 14:24:53.297] The optimal number of layers: 2\n",
      "[2025-06-09 14:24:53.298] Start to evalute the model:\n",
      "[2025-06-09 14:24:53.298] Evaluating cascade layer = 0 \n",
      "[2025-06-09 14:24:53.300] Evaluating cascade layer = 1 \n",
      "\n",
      "Testing Accuracy: 77.000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\\forest.py:497: UserWarning: Some inputs do not have OOB predictions. This probably means too few trees were used to compute any reliable oob predictions.\n",
      "  \"Some inputs do not have OOB predictions. \"\n",
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\\forest.py:504: RuntimeWarning: invalid value encountered in true_divide\n",
      "  / oob_decision_function.sum(axis=1)[:, np.newaxis]\n",
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\\forest.py:497: UserWarning: Some inputs do not have OOB predictions. This probably means too few trees were used to compute any reliable oob predictions.\n",
      "  \"Some inputs do not have OOB predictions. \"\n",
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\\forest.py:504: RuntimeWarning: invalid value encountered in true_divide\n",
      "  / oob_decision_function.sum(axis=1)[:, np.newaxis]\n",
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\\forest.py:497: UserWarning: Some inputs do not have OOB predictions. This probably means too few trees were used to compute any reliable oob predictions.\n",
      "  \"Some inputs do not have OOB predictions. \"\n",
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\\forest.py:504: RuntimeWarning: invalid value encountered in true_divide\n",
      "  / oob_decision_function.sum(axis=1)[:, np.newaxis]\n",
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\\forest.py:497: UserWarning: Some inputs do not have OOB predictions. This probably means too few trees were used to compute any reliable oob predictions.\n",
      "  \"Some inputs do not have OOB predictions. \"\n",
      "C:\\Users\\carlo\\Desktop\\project\\Deep-Forest\\deepforest\\forest.py:504: RuntimeWarning: invalid value encountered in true_divide\n",
      "  / oob_decision_function.sum(axis=1)[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "print(os.path.dirname(df.__file__))\n",
    "model = df.CascadeForestClassifier(   \n",
    "    n_bins=n_classes,     \n",
    "    n_estimators=2, # Forests sets (RF + ExtraRF) per layer\n",
    "    n_trees=10, # Trees per forest\n",
    "    max_depth=10,\n",
    "    n_jobs=1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred) * 100\n",
    "print(\"\\nTesting Accuracy: {:.3f} %\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a279155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 80.000 %\n"
     ]
    }
   ],
   "source": [
    "model = PRF4DF.SklearnCompatiblePRF(\n",
    "    n_classes_= n_classes,\n",
    "    n_features_= n_features,\n",
    "    use_probabilistic_labels=False, \n",
    "    use_feature_uncertainties=True,\n",
    "    n_estimators=10, # Trees per forest\n",
    "    max_depth=10,\n",
    "    n_jobs=1\n",
    ")\n",
    "model.fit(X_train_combined, y_train)\n",
    "accuracy = model.score(X_test_combined, y_test) * 100\n",
    "print(f\"Testing Accuracy: {accuracy:.3f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
